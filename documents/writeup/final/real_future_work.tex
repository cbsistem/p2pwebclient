% currently not included in the Thesis.

A few more aggressive optimizations would also be potential in a download system such as this.  For example TCP doesn't ramp-up as quickly as one would like it to for new connections.  Transferring over UDP with a custom-built protocol might be faster\footenote{For example, Google called recently for a new version of TCP http://www.pcworld.com/article/167360/whats\_behind\_googles\_speed\_push.html}

Another very interesting idea would be also include some means of ``cataloging'' existing files on the Internet (i.e. automatic mirror creation lists of existing content).  For example if a download is offered by 10 sources, being able to instantly know and download from all 10 is like having 10 instant seeds.  There is a file type called a ``univeral download'' (or something of the sort) that lists mirrors for certain files, as well as BitTorrent itself has a couple of extension protocol for using HTTP mirrors as seeds, however, these are not automatically setup and would require server changes.  GetRight also does something similar by automatically binding files to mirrors.  The author attempted to convince GetRight of the usefulness of an automatic BitTorrent style download, but it has yet to appear, and may be for commercial use only.

% BitTorrent is described as ``still not for the faint in heart'' here: http://download.cnet.com/uTorrent/3000-2196\_4-10528327.html

Another not explored venue is security.  For example how do you know a file is the same as that found on the origin server?  Some ideas would be to *sample* the origin server for pieces, to make sure they match, to note that some FTP sites have md5 capabilities on their files (and some web servers do), to scrape websites to look for published .md5's, to create an XOR of the contents of blocks so that one could compare md5's as they come in, to use some type of P2P trust system, etc. etc.  For now our system assumes trustworthy clients.  There's also an HTTP header returned per file that might be useful.  One could also have designated servers act as ``sentinels'' downloading files only to verify their md5 sums (though this obviously breaks down with scale and very large files, it has potential).

Another interesting merger would be to combine BitTorrent with this protocol, for downloads.  Or to just use the BitTorrent protocol, or what not.

Another potential it also has is, since it requires use of a proxy, one could use it to implement a new dns layer, a la p2p://name.files or even http://name.p2p or what not.  One could also use this system to ``publish'' files which are published then no longer stored locally [i.e. rely solely on downloaders to continue publishing files].

Peers upload blocks of a file at the same time they are downloading others.  It might be worth putting some type of cap on upload speed while downloading a file, to allow for TCP to continue the download at top speed.  It has been noted that peer upload download speed is limited by upload speed in some cases \cite{google_note}.

Note also that connecting several times to the origin (even if no peers were present), at times helps with download speeds, if only because of the shaping algorithms employed by some internet providers.

It would be interesting to create a solution similar to this one that integrated Apache with BitTorrent, and FireFox with BitTorrent (with or without the DHT).  This is similar to what we do in this Thesis, if less easy to deploy

When building a better rendezvous system, it might be nice to examine that used in industry (BitTorrent, Azureus, Dijjer) to see how they accomplish the same.

Similar to torrentFlux\cite{torrentFlux} it might be interesting to build something in php which could serve the appropriate files or download them.

Are there other BitTorrent plugin optimizations that would be useful? What about NAT traversal (or instant NAT traversal)?  Which DHT's are fastest/most apt for this work?

Could you establish some type of ``push'' mechanism, i.e. you note in the DHT ``if anyone ever gets block X, I want it'' -- then when a peer completes a download of block X, it can immediately contact and serve that block? (Or something that doesn't require polling).  Also quite useful would be to have some dedicated caches (perhaps they can list themselves somewhere?) that you access after downloading an uncommon file--they'll cache it for you.  Related to this is CoDeen (and/or CoBlitz) will allow a single peer to download a file and as it receives blocks it will stream them out in a tree-like fashion to peers that have contacted it and are waiting for the block.  Also related is an idea to try to use commercial sites for this http://www.ruby-forum.com/topic/189241.

Local peer discovery (via UDP) would also be useful (recent BYU thesis, existent protocols that do this for BitTorrent).

Another interesting facet would be exploring its usefulness in streaming.  Another would be exploring its use as a ``backup'' to no longer existing files.  Another would be to explore privacy and/or security and/or trust issues.
